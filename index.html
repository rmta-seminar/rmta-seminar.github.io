<html xmlns="http://www.w3.org/1999/xhtml">
<head>

<meta http-equiv="content-type" content="text/html; charset=UTF-8" />
<link rel="stylesheet" href="styles.css">


<title>Online Seminar: Random Matrix Theory and Applications</title>

<style>
div {
  margin-top: 80px;
  margin-bottom: 80px;
  margin-right: 50px;
  margin-left: 50px;
}


 a:link {
    color: blue;
        text-decoration: none;
}

/* visited link */
a:visited {
    color: blue;
    text-decoration: none;
}

/* mouse over link */
a:hover {
    color: blue;
        text-decoration: none;
}

/* selected link */
a:active {
    color: blue;
        text-decoration: none;
}    
</style>

        
</head>




<body>



                
           <div> <id="content">

   
             

           
           <center><h1> Online Seminar: Random Matrix Theory and Applications</h1></center>
     
            


           <div>  <h2>Introduction:</h2>

          <big>
               
              <p> This seminar aims to cover topics on both the theoretical and applied aspects of random matrix theory and related fields. 
                
              </p> 

               <p>
                 
                The meetings will be held on Zoom and typically scheduled monthly on Thursdays in Beijing Time (UTC/GMT +8 hours).
             
             </p> 


             <p>
                   If you want to join the mailing list, please send an email to <a class="zwei" href="mailto:rmta-seminar+subscribe@googlegroups.com"> rmta-seminar+subscribe AT googlegroups DOT com.</a><br>
                   You will be asked to log in to your Google account for the subscription.<br>
                   Otherwise, if you do not have a Google account, please contact <a class="zwei" href="mailto:rmta.seminar@gmail.com"> rmta.seminar AT gmail DOT com.</a>
             </p>
           </big> 
 
           </div>  




    

          <div> <h2>Organizers:</h2>
   
               <big>
             
               <p style="line-height: 1.5em">  
                       Zhigang Bao (University of Hong Kong) <br>
                       Zhenyu Liao (Huazhong University of Science & Technology) <br>
                       Yuanyuan Xu (AMSS, Chinese Academy of Sciences)<br>
                       Lun Zhang (Fudan University) 
               </p>

           </big> 

          </div>  





             <div> <h2>Upcoming seminars:</h2>

                 <h3>Year 2025:</h3>

             <big>
                  
                  <ul>


                           <li style="line-height: 1.5em">
                              <b>Date:</b> <span style="color:Tomato;">9:30-10:30 am</span> (Beijing Time), June 12, 2025  <br>
                              <b>Speaker:</b> <a href="https://elliotpaquette.github.io/">Elliot Paquette (McGill University)</a> <br>
                              <p>
                                <b>Title:</b> From magic squares, through random matrices, and to the multiplicative chaos <br>
                                <b>Abstract:</b> In 2004, motivated by connections of random matrix theory to number theory, Diaconis and Gamburd showed a fascinating connection between the enumeration problem of magic squares (squares filled integers with row and column sum constraints) and the moments of the ‘secular coefficients’ of random matrices, when the size of the matrix tends to infinity.  These are the coefficients in the monomial expansion of a characteristic polynomial, or equivalently, the elementary symmetric polynomials of the eigenvalues of this random matrix.

                                It turns out that this characteristic polynomial has a limit, when the matrix size tends to infinity.  It converges to a random fractal, the holomorphic multiplicative chaos.  We describe this process on the unit circle, and show how it can be connected even more strongly to random matrices, and how magic square combinatorics are a type of ‘signature’ of this holomorphic multiplicative chaos.  We’ll review some open questions about these objects, and discuss some links between this and other stochastic processes such as the Gaussian multiplicative chaos, the circular beta-ensemble and random multiplicative function.

                              </p>
                          </li>   


                    <br><br><br>


                           <li style="line-height: 1.5em">
                              <b>Date:</b> 9:00-10:00 am (Beijing Time), July 31, 2025  <br>
                              <b>Speaker:</b> <a href="https://www.stat.berkeley.edu/~vadicgor/">Vadim Gorin (UC Berkeley)</a> <br>
                              <p>
                                <b>Title:</b> TBA <br>
                                <b>Abstract:</b> TBA

                              </p>
                          </li>   


                     <br><br><br>


                    
                  
                  </ul>                 
                  
                   
           </big>
           </div> 
        


          

            <div> <h2>Past seminars:</h2>


               <h3>Year 2025:</h3>

               <big>


                 <ul>
                          <li style="line-height: 1.5em"> 
                              <b>Date:</b> 9:00-10:00 am (Beijing Time), April 17, 2025  <br>
                              <b>Speaker:</b> <a href="https://dms.umontreal.ca/~benignil/">Lucas Benigni (Université de Montréal)</a> <br>
                              <p>
                                <b>Title:</b> Spectrum of the Neural Tangent Kernel in a quadratic scaling <br>
                                <b>Abstract:</b>Despite their surplus of parameters, modern deep learning models often generalize well, a phenomenon exemplified by the "double descent curve." 
                              While this behavior is theoretically grasped for problems such as ridge regression under linear scaling of dimensions, intriguing phenomenon emerge under quadratic scaling, where sample size equals parameter count. 
                             In this presentation, we study the eigenvalues of the Neural Tangent Kernel, a matrix model pertinent to wide neural networks trained via gradient descent, within this quadratic regime.
                             </p>
                          </li>


                          <br><br><br>


                           <li style="line-height: 1.5em">
                              <b>Date:</b> 9:00-10:00 am (Beijing Time), April 24, 2025  <br>
                              <b>Speaker:</b> <a href="https://jiaoyang.github.io">Jiaoyang Huang (University of Pennsylvania)</a> <br>
                              
                             <p>
                               <b>Title:</b> Ramanujan Property and Edge Universality of Random Regular Graphs <br>
                              <b>Abstract:</b> Extremal eigenvalues of graphs are of particular interest in theoretical computer science and combinatorics. 
                             Specifically, the spectral gap—the difference between the largest and second-largest eigenvalues—measures the expansion properties of a graph. 
                             In this talk, I will focus on random d-regular graphs.
                             
                             <br>

                             I will begin by providing background on the eigenvalues of random d-regular graphs and their connections to random matrix theory. 
                             In the second part of the talk, I will discuss our recent results on eigenvalue rigidity and edge universality for these graphs. 
                             Eigenvalue rigidity asserts that, with high probability, each eigenvalue concentrates around its classical location as predicted by the Kesten-McKay distribution. 
                             Edge universality states that the second-largest eigenvalue and the smallest eigenvalue of random d-regular graphs converge to the Tracy-Widom distribution from the Gaussian Orthogonal Ensemble. 
                             Consequently, approximately 69% of d-regular graphs are Ramanujan graphs. This work is based on joint work with Theo McKenzie and Horng-Tzer Yau.<br>
                            </p>

                          </li>


                          <br><br><br>

                          <li style="line-height: 1.5em">
                              <b>Date:</b> 9:00-10:00 am (Beijing Time), May 22, 2025  <br>
                              <b>Speaker:</b> <a href="http://www.stat.yale.edu/~zf59/">Zhou Fan (Yale University)</a> <br>
                              <p>
                                <b>Title:</b> Kronecker-product random matrices and a matrix least squares problem <br>
                                <b>Abstract:</b> We study the eigenvalue distribution and resolvent of a Kronecker-product random matrix model, which has a mean-field structure in each Kronecker factor but not a global mean-field structure over all variables. Our main results are a quantitative approximation for the Stieltjes transform, a deterministic equivalent approximation for the resolvent, and sharp estimates for entries and blocks of the resolvent on global spectral scales. Our study is motivated by consideration of a matrix-valued least-squares optimization problem, where the dimension of the optimization variable is comparable to the dimensions of the random input matrices of the problem. Our analyses imply an asymptotic characterization of the optimal solution and its associated optimal objective value.

                                This is joint work with Renyuan Ma.
                              </p>
                          </li> 


                          <br><br><br>
                  
                  </ul>         


             </big>


            </div> 








        <center><img src="logo.jpg" height="200" alt="RMTA"/></center>




 </div> 
           



</body>
</html>
